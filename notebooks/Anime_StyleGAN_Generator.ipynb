{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import math"
      ],
      "metadata": {
        "id": "23cVuI9CkA_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp_a1Alljym1"
      },
      "outputs": [],
      "source": [
        "def show_tensor_images(image_tensor, img_name , num_images=16, size=(3, 64, 64)):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images,\n",
        "    size per image, and images per row, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu().clamp_(0, 1)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=4, padding=0)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{img_name}\" , bbox_inches='tight', pad_inches=0, dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Taken from https://github.com/rosinality/style-based-gan-pytorch/blob/master/model.py '''\n",
        "from torch.nn import init\n",
        "from torch.autograd import Function\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "def init_linear(linear):\n",
        "    init.xavier_normal(linear.weight)\n",
        "    linear.bias.data.zero_()\n",
        "\n",
        "\n",
        "def init_conv(conv, glu=True):\n",
        "    init.kaiming_normal(conv.weight)\n",
        "    if conv.bias is not None:\n",
        "        conv.bias.data.zero_()\n",
        "\n",
        "\n",
        "class EqualLR:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def compute_weight(self, module):\n",
        "        weight = getattr(module, self.name + '_orig')\n",
        "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
        "\n",
        "        return weight * sqrt(2 / fan_in)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply(module, name):\n",
        "        fn = EqualLR(name)\n",
        "\n",
        "        weight = getattr(module, name)\n",
        "        del module._parameters[name]\n",
        "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
        "        module.register_forward_pre_hook(fn)\n",
        "\n",
        "        return fn\n",
        "\n",
        "    def __call__(self, module, input):\n",
        "        weight = self.compute_weight(module)\n",
        "        setattr(module, self.name, weight)\n",
        "\n",
        "\n",
        "def equal_lr(module, name='weight'):\n",
        "    EqualLR.apply(module, name)\n",
        "\n",
        "    return module\n",
        "\n",
        "\n",
        "class FusedUpsample(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, padding=0):\n",
        "        super().__init__()\n",
        "\n",
        "        weight = torch.randn(in_channel, out_channel, kernel_size, kernel_size)\n",
        "        bias = torch.zeros(out_channel)\n",
        "\n",
        "        fan_in = in_channel * kernel_size * kernel_size\n",
        "        self.multiplier = sqrt(2 / fan_in)\n",
        "\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        self.bias = nn.Parameter(bias)\n",
        "\n",
        "        self.pad = padding\n",
        "\n",
        "    def forward(self, input):\n",
        "        weight = F.pad(self.weight * self.multiplier, [1, 1, 1, 1])\n",
        "        weight = (\n",
        "            weight[:, :, 1:, 1:]\n",
        "            + weight[:, :, :-1, 1:]\n",
        "            + weight[:, :, 1:, :-1]\n",
        "            + weight[:, :, :-1, :-1]\n",
        "        ) / 4\n",
        "\n",
        "        out = F.conv_transpose2d(input, weight, self.bias, stride=2, padding=self.pad)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class FusedDownsample(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, padding=0):\n",
        "        super().__init__()\n",
        "\n",
        "        weight = torch.randn(out_channel, in_channel, kernel_size, kernel_size)\n",
        "        bias = torch.zeros(out_channel)\n",
        "\n",
        "        fan_in = in_channel * kernel_size * kernel_size\n",
        "        self.multiplier = sqrt(2 / fan_in)\n",
        "\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        self.bias = nn.Parameter(bias)\n",
        "\n",
        "        self.pad = padding\n",
        "\n",
        "    def forward(self, input):\n",
        "        weight = F.pad(self.weight * self.multiplier, [1, 1, 1, 1])\n",
        "        weight = (\n",
        "            weight[:, :, 1:, 1:]\n",
        "            + weight[:, :, :-1, 1:]\n",
        "            + weight[:, :, 1:, :-1]\n",
        "            + weight[:, :, :-1, :-1]\n",
        "        ) / 4\n",
        "\n",
        "        out = F.conv2d(input, weight, self.bias, stride=2, padding=self.pad)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "\n",
        "class BlurFunctionBackward(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, grad_output, kernel, kernel_flip):\n",
        "        ctx.save_for_backward(kernel, kernel_flip)\n",
        "\n",
        "        grad_input = F.conv2d(\n",
        "            grad_output, kernel_flip, padding=1, groups=grad_output.shape[1]\n",
        "        )\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, gradgrad_output):\n",
        "        kernel, kernel_flip = ctx.saved_tensors\n",
        "\n",
        "        grad_input = F.conv2d(\n",
        "            gradgrad_output, kernel, padding=1, groups=gradgrad_output.shape[1]\n",
        "        )\n",
        "\n",
        "        return grad_input, None, None\n",
        "\n",
        "\n",
        "class BlurFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, kernel, kernel_flip):\n",
        "        ctx.save_for_backward(kernel, kernel_flip)\n",
        "\n",
        "        output = F.conv2d(input, kernel, padding=1, groups=input.shape[1])\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        kernel, kernel_flip = ctx.saved_tensors\n",
        "\n",
        "        grad_input = BlurFunctionBackward.apply(grad_output, kernel, kernel_flip)\n",
        "\n",
        "        return grad_input, None, None\n",
        "\n",
        "\n",
        "blur = BlurFunction.apply\n",
        "\n",
        "\n",
        "class Blur(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "\n",
        "        weight = torch.tensor([[1, 2, 1], [2, 4, 2], [1, 2, 1]], dtype=torch.float32)\n",
        "        weight = weight.view(1, 1, 3, 3)\n",
        "        weight = weight / weight.sum()\n",
        "        weight_flip = torch.flip(weight, [2, 3])\n",
        "\n",
        "        self.register_buffer('weight', weight.repeat(channel, 1, 1, 1))\n",
        "        self.register_buffer('weight_flip', weight_flip.repeat(channel, 1, 1, 1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return blur(input, self.weight, self.weight_flip)\n",
        "        # return F.conv2d(input, self.weight, padding=1, groups=input.shape[1])\n",
        "\n",
        "\n",
        "class EqualConv2d(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        conv = nn.Conv2d(*args, **kwargs)\n",
        "        conv.weight.data.normal_()\n",
        "        conv.bias.data.zero_()\n",
        "        self.conv = equal_lr(conv)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.conv(input)\n",
        "\n",
        "\n",
        "class EqualLinear(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        linear = nn.Linear(in_dim, out_dim)\n",
        "        linear.weight.data.normal_()\n",
        "        linear.bias.data.zero_()\n",
        "\n",
        "        self.linear = equal_lr(linear)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.linear(input)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        kernel_size,\n",
        "        padding,\n",
        "        kernel_size2=None,\n",
        "        padding2=None,\n",
        "        downsample=False,\n",
        "        fused=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        pad1 = padding\n",
        "        pad2 = padding\n",
        "        if padding2 is not None:\n",
        "            pad2 = padding2\n",
        "\n",
        "        kernel1 = kernel_size\n",
        "        kernel2 = kernel_size\n",
        "        if kernel_size2 is not None:\n",
        "            kernel2 = kernel_size2\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            EqualConv2d(in_channel, out_channel, kernel1, padding=pad1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        if downsample:\n",
        "            if fused:\n",
        "                self.conv2 = nn.Sequential(\n",
        "                    Blur(out_channel),\n",
        "                    FusedDownsample(out_channel, out_channel, kernel2, padding=pad2),\n",
        "                    nn.LeakyReLU(0.2),\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                self.conv2 = nn.Sequential(\n",
        "                    Blur(out_channel),\n",
        "                    EqualConv2d(out_channel, out_channel, kernel2, padding=pad2),\n",
        "                    nn.AvgPool2d(2),\n",
        "                    nn.LeakyReLU(0.2),\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            self.conv2 = nn.Sequential(\n",
        "                EqualConv2d(out_channel, out_channel, kernel2, padding=pad2),\n",
        "                nn.LeakyReLU(0.2),\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.conv1(input)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class AdaptiveInstanceNorm(nn.Module):\n",
        "    def __init__(self, in_channel, style_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.InstanceNorm2d(in_channel)\n",
        "        self.style = EqualLinear(style_dim, in_channel * 2)\n",
        "\n",
        "        self.style.linear.bias.data[:in_channel] = 1\n",
        "        self.style.linear.bias.data[in_channel:] = 0\n",
        "\n",
        "    def forward(self, input, style):\n",
        "        style = self.style(style).unsqueeze(2).unsqueeze(3)\n",
        "        gamma, beta = style.chunk(2, 1)\n",
        "\n",
        "        out = self.norm(input)\n",
        "        out = gamma * out + beta\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class NoiseInjection(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight = nn.Parameter(torch.zeros(1, channel, 1, 1))\n",
        "\n",
        "    def forward(self, image, noise):\n",
        "        return image + self.weight * noise\n",
        "\n",
        "\n",
        "class ConstantInput(nn.Module):\n",
        "    def __init__(self, channel, size=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input = nn.Parameter(torch.randn(1, channel, size, size))\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch = input.shape[0]\n",
        "        out = self.input.repeat(batch, 1, 1, 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StyledConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        kernel_size=3,\n",
        "        padding=1,\n",
        "        style_dim=512,\n",
        "        initial=False,\n",
        "        upsample=False,\n",
        "        fused=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if initial:\n",
        "            self.conv1 = ConstantInput(in_channel)\n",
        "\n",
        "        else:\n",
        "            if upsample:\n",
        "                if fused:\n",
        "                    self.conv1 = nn.Sequential(\n",
        "                        FusedUpsample(\n",
        "                            in_channel, out_channel, kernel_size, padding=padding\n",
        "                        ),\n",
        "                        Blur(out_channel),\n",
        "                    )\n",
        "\n",
        "                else:\n",
        "                    self.conv1 = nn.Sequential(\n",
        "                        nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                        EqualConv2d(\n",
        "                            in_channel, out_channel, kernel_size, padding=padding\n",
        "                        ),\n",
        "                        Blur(out_channel),\n",
        "                    )\n",
        "\n",
        "            else:\n",
        "                self.conv1 = EqualConv2d(\n",
        "                    in_channel, out_channel, kernel_size, padding=padding\n",
        "                )\n",
        "\n",
        "        self.noise1 = equal_lr(NoiseInjection(out_channel))\n",
        "        self.adain1 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
        "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.conv2 = EqualConv2d(out_channel, out_channel, kernel_size, padding=padding)\n",
        "        self.noise2 = equal_lr(NoiseInjection(out_channel))\n",
        "        self.adain2 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
        "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, input, style, noise):\n",
        "        out = self.conv1(input)\n",
        "        out = self.noise1(out, noise)\n",
        "        out = self.lrelu1(out)\n",
        "        out = self.adain1(out, style)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.noise2(out, noise)\n",
        "        out = self.lrelu2(out)\n",
        "        out = self.adain2(out, style)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, code_dim, fused=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.progression = nn.ModuleList(\n",
        "            [\n",
        "                StyledConvBlock(512, 512, 3, 1, initial=True),  # 4\n",
        "                StyledConvBlock(512, 512, 3, 1, upsample=True),  # 8\n",
        "                StyledConvBlock(512, 512, 3, 1, upsample=True),  # 16\n",
        "                StyledConvBlock(512, 512, 3, 1, upsample=True),  # 32\n",
        "                StyledConvBlock(512, 256, 3, 1, upsample=True),  # 64\n",
        "                StyledConvBlock(256, 128, 3, 1, upsample=True, fused=fused),  # 128\n",
        "                StyledConvBlock(128, 64, 3, 1, upsample=True, fused=fused),  # 256\n",
        "                StyledConvBlock(64, 32, 3, 1, upsample=True, fused=fused),  # 512\n",
        "                StyledConvBlock(32, 16, 3, 1, upsample=True, fused=fused),  # 1024\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.to_rgb = nn.ModuleList(\n",
        "            [\n",
        "                EqualConv2d(512, 3, 1),\n",
        "                EqualConv2d(512, 3, 1),\n",
        "                EqualConv2d(512, 3, 1),\n",
        "                EqualConv2d(512, 3, 1),\n",
        "                EqualConv2d(256, 3, 1),\n",
        "                EqualConv2d(128, 3, 1),\n",
        "                EqualConv2d(64, 3, 1),\n",
        "                EqualConv2d(32, 3, 1),\n",
        "                EqualConv2d(16, 3, 1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # self.blur = Blur()\n",
        "\n",
        "    def forward(self, style, noise, step=0, alpha=-1, mixing_range=(-1, -1)):\n",
        "        out = noise[0]\n",
        "\n",
        "        if len(style) < 2:\n",
        "            inject_index = [len(self.progression) + 1]\n",
        "\n",
        "        else:\n",
        "            inject_index = sorted(random.sample(list(range(step)), len(style) - 1))\n",
        "\n",
        "        crossover = 0\n",
        "\n",
        "        for i, (conv, to_rgb) in enumerate(zip(self.progression, self.to_rgb)):\n",
        "            if mixing_range == (-1, -1):\n",
        "                if crossover < len(inject_index) and i > inject_index[crossover]:\n",
        "                    crossover = min(crossover + 1, len(style))\n",
        "\n",
        "                style_step = style[crossover]\n",
        "\n",
        "            else:\n",
        "                if mixing_range[0] <= i <= mixing_range[1]:\n",
        "                    style_step = style[1]\n",
        "\n",
        "                else:\n",
        "                    style_step = style[0]\n",
        "\n",
        "            if i > 0 and step > 0:\n",
        "                out_prev = out\n",
        "\n",
        "            out = conv(out, style_step, noise[i])\n",
        "\n",
        "            if i == step:\n",
        "                out = to_rgb(out)\n",
        "\n",
        "                if i > 0 and 0 <= alpha < 1:\n",
        "                    skip_rgb = self.to_rgb[i - 1](out_prev)\n",
        "                    skip_rgb = F.interpolate(skip_rgb, scale_factor=2, mode='nearest')\n",
        "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
        "\n",
        "                break\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StyledGenerator(nn.Module):\n",
        "    def __init__(self, code_dim=512, n_mlp=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.generator = Generator(code_dim)\n",
        "\n",
        "        layers = [PixelNorm()]\n",
        "        for i in range(n_mlp):\n",
        "            layers.append(EqualLinear(code_dim, code_dim))\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "\n",
        "        self.style = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input,\n",
        "        noise=None,\n",
        "        step=0,\n",
        "        alpha=-1,\n",
        "        mean_style=None,\n",
        "        style_weight=0,\n",
        "        mixing_range=(-1, -1),\n",
        "    ):\n",
        "        styles = []\n",
        "        if type(input) not in (list, tuple):\n",
        "            input = [input]\n",
        "\n",
        "        for i in input:\n",
        "            styles.append(self.style(i))\n",
        "\n",
        "        batch = input[0].shape[0]\n",
        "\n",
        "        if noise is None:\n",
        "            noise = []\n",
        "\n",
        "            for i in range(step + 1):\n",
        "                size = 4 * 2 ** i\n",
        "                noise.append(torch.randn(batch, 1, size, size, device=input[0].device))\n",
        "\n",
        "        if mean_style is not None:\n",
        "            styles_norm = []\n",
        "\n",
        "            for style in styles:\n",
        "                styles_norm.append(mean_style + style_weight * (style - mean_style))\n",
        "\n",
        "            styles = styles_norm\n",
        "\n",
        "        return self.generator(styles, noise, step, alpha, mixing_range=mixing_range)\n",
        "\n",
        "    def mean_style(self, input):\n",
        "        style = self.style(input).mean(0, keepdim=True)\n",
        "\n",
        "        return style\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, fused=True, from_rgb_activate=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.progression = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(16, 32, 3, 1, downsample=True, fused=fused),  # 512\n",
        "                ConvBlock(32, 64, 3, 1, downsample=True, fused=fused),  # 256\n",
        "                ConvBlock(64, 128, 3, 1, downsample=True, fused=fused),  # 128\n",
        "                ConvBlock(128, 256, 3, 1, downsample=True, fused=fused),  # 64\n",
        "                ConvBlock(256, 512, 3, 1, downsample=True),  # 32\n",
        "                ConvBlock(512, 512, 3, 1, downsample=True),  # 16\n",
        "                ConvBlock(512, 512, 3, 1, downsample=True),  # 8\n",
        "                ConvBlock(512, 512, 3, 1, downsample=True),  # 4\n",
        "                ConvBlock(513, 512, 3, 1, 4, 0),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        def make_from_rgb(out_channel):\n",
        "            if from_rgb_activate:\n",
        "                return nn.Sequential(EqualConv2d(3, out_channel, 1), nn.LeakyReLU(0.2))\n",
        "\n",
        "            else:\n",
        "                return EqualConv2d(3, out_channel, 1)\n",
        "\n",
        "        self.from_rgb = nn.ModuleList(\n",
        "            [\n",
        "                make_from_rgb(16),\n",
        "                make_from_rgb(32),\n",
        "                make_from_rgb(64),\n",
        "                make_from_rgb(128),\n",
        "                make_from_rgb(256),\n",
        "                make_from_rgb(512),\n",
        "                make_from_rgb(512),\n",
        "                make_from_rgb(512),\n",
        "                make_from_rgb(512),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # self.blur = Blur()\n",
        "\n",
        "        self.n_layer = len(self.progression)\n",
        "\n",
        "        self.linear = EqualLinear(512, 1)\n",
        "\n",
        "    def forward(self, input, step=0, alpha=-1):\n",
        "        for i in range(step, -1, -1):\n",
        "            index = self.n_layer - i - 1\n",
        "\n",
        "            if i == step:\n",
        "                out = self.from_rgb[index](input)\n",
        "\n",
        "            if i == 0:\n",
        "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
        "                mean_std = out_std.mean()\n",
        "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
        "                out = torch.cat([out, mean_std], 1)\n",
        "\n",
        "            out = self.progression[index](out)\n",
        "\n",
        "            if i > 0:\n",
        "                if i == step and 0 <= alpha < 1:\n",
        "                    skip_rgb = F.avg_pool2d(input, 2)\n",
        "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
        "\n",
        "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
        "\n",
        "        out = out.squeeze(2).squeeze(2)\n",
        "        # print(input.size(), out.size(), step)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "kDecCy1IkFyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gdown\n",
        "import gdown\n",
        "def download_file_from_google_drive(file_id, output_file):\n",
        "    \"\"\"\n",
        "    Download a file from Google Drive.\n",
        "\n",
        "    :param file_id: The Google Drive file ID.\n",
        "    :param output_file: The name of the file to save.\n",
        "    \"\"\"\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, output_file, quiet=False)\n",
        "\n",
        "# Example usage:\n",
        "file_id = \"1-Iz1UHBRNlOQIZa44eEb0_2tTz85o9Ry\"\n",
        "file_out = \"stylegan-step=4000.pt\"\n",
        "download_file_from_google_drive(file_id, file_out)"
      ],
      "metadata": {
        "id": "2UMUA__Tklat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some helper functions for inference\n",
        "def mean_style(generator, code_dim, device, batch=1024, batches=10):\n",
        "    '''\n",
        "    Function that computes the mean style vector.\n",
        "    '''\n",
        "    mean_style = []\n",
        "    for i in range(batches):\n",
        "        z = torch.randn(batch, code_dim).to(device)\n",
        "        style = generator.mean_style(z)\n",
        "        mean_style += [style]\n",
        "\n",
        "    mean_style = torch.stack(mean_style, dim=0).mean(0)\n",
        "    return mean_style\n",
        "def synthesize(generator, n_samples, code_dim, device):\n",
        "    '''\n",
        "    Function that samples random noise and generates a fake image.\n",
        "    '''\n",
        "    generator.eval()\n",
        "    z = torch.randn(n_samples, code_dim, device=device)\n",
        "    global mean_style_\n",
        "    mean_style_ = mean_style(generator, code_dim, device)\n",
        "    x = generator(z, step=step, alpha=1, mean_style=mean_style_, style_weight=0.7)\n",
        "    return x"
      ],
      "metadata": {
        "id": "PyPjuwpbkWqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resolution = 256\n",
        "step = int(math.log2(resolution / 4))\n",
        "checkpoint = torch.load('stylegan-step=4000.pt')\n",
        "code_dim=512\n",
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "CotXHX8Tk9Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(n_samples , checkpoint=checkpoint , code_dim=code_dim , device=device) :\n",
        "  # Load checkpoint\n",
        "  generator = StyledGenerator(code_dim=code_dim).to(device)\n",
        "  generator.load_state_dict(checkpoint['generator'])\n",
        "\n",
        "  # Run inference\n",
        "  x = synthesize(generator, n_samples, code_dim, device)\n",
        "  show_tensor_images(x , \"result\")"
      ],
      "metadata": {
        "id": "BpStud1nk7un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(n_samples=30 , checkpoint=checkpoint , code_dim=code_dim , device=device)"
      ],
      "metadata": {
        "id": "jALp89n-kh4o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}